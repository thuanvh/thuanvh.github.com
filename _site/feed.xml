<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-05-03T00:00:39+07:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">A bla bla developer blog</title><subtitle>Work note.</subtitle><entry><title type="html">Welcome to Jekyll!</title><link href="http://localhost:4000/jekyll/update/2020/05/02/welcome-to-jekyll.html" rel="alternate" type="text/html" title="Welcome to Jekyll!" /><published>2020-05-02T01:17:24+07:00</published><updated>2020-05-02T01:17:24+07:00</updated><id>http://localhost:4000/jekyll/update/2020/05/02/welcome-to-jekyll</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2020/05/02/welcome-to-jekyll.html">&lt;p&gt;You’ll find this post in your &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_posts&lt;/code&gt; directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;jekyll serve&lt;/code&gt;, which launches a web server and auto-regenerates your site when a file is updated.&lt;/p&gt;

&lt;p&gt;To add new posts, simply add a file in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_posts&lt;/code&gt; directory that follows the convention &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;YYYY-MM-DD-name-of-post.ext&lt;/code&gt; and includes the necessary front matter. Take a look at the source for this post to get an idea about how it works.&lt;/p&gt;

&lt;p&gt;Jekyll also offers powerful support for code snippets:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;print_hi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;nb&quot;&gt;puts&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Hi, &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;#{&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;print_hi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'Tom'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#=&amp;gt; prints 'Hi, Tom' to STDOUT.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Check out the &lt;a href=&quot;https://jekyllrb.com/docs/home&quot;&gt;Jekyll docs&lt;/a&gt; for more info on how to get the most out of Jekyll. File all bugs/feature requests at &lt;a href=&quot;https://github.com/jekyll/jekyll&quot;&gt;Jekyll’s GitHub repo&lt;/a&gt;. If you have questions, you can ask them on &lt;a href=&quot;https://talk.jekyllrb.com/&quot;&gt;Jekyll Talk&lt;/a&gt;.&lt;/p&gt;</content><author><name></name></author><summary type="html">You’ll find this post in your _posts directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run jekyll serve, which launches a web server and auto-regenerates your site when a file is updated.</summary></entry><entry><title type="html">Speed up python code</title><link href="http://localhost:4000/2020/04/03/speed-up-python-code/" rel="alternate" type="text/html" title="Speed up python code" /><published>2020-04-03T05:58:57+07:00</published><updated>2020-04-03T05:58:57+07:00</updated><id>http://localhost:4000/2020/04/03/speed-up-python-code</id><content type="html" xml:base="http://localhost:4000/2020/04/03/speed-up-python-code/">&lt;p&gt;https://towardsdatascience.com/how-to-speed-up-your-python-code-d31927691012&lt;/p&gt;

&lt;p&gt;I have read a few analyse in using python :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Optimize your code first&lt;/li&gt;
  &lt;li&gt;Use pypy library&lt;/li&gt;
  &lt;li&gt;Use multithread for IO bound or asyncio&lt;/li&gt;
  &lt;li&gt;Use multiprocess for CPU bound&lt;/li&gt;
  &lt;li&gt;Use hadoop for distributed computing for move to cloud&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">https://towardsdatascience.com/how-to-speed-up-your-python-code-d31927691012</summary></entry><entry><title type="html">Training Parallelism</title><link href="http://localhost:4000/2020/03/28/training-parallelism/" rel="alternate" type="text/html" title="Training Parallelism" /><published>2020-03-28T16:46:30+07:00</published><updated>2020-03-28T16:46:30+07:00</updated><id>http://localhost:4000/2020/03/28/training-parallelism</id><content type="html" xml:base="http://localhost:4000/2020/03/28/training-parallelism/">&lt;p&gt;&lt;strong&gt;Training with memory limit&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;One of interesting test about training with memory limit. He use the way to store some nodes in forward steps (not all nodes). Then in backward steps, he recalculate some forward steps (which is not stored) for gradient calculation. The nodes indexes which are stored are sqrt(i)-th node.&lt;/p&gt;

&lt;p&gt;https://github.com/cybertronai/gradient-checkpointing&lt;/p&gt;

&lt;p&gt;And he wrote a post about this technique:&lt;/p&gt;

&lt;p&gt;https://medium.com/tensorflow/fitting-larger-networks-into-memory-583e3c758ff9&lt;/p&gt;

&lt;p&gt;And the checkpoint concept is used in PyTorch also. The same concept with the above idea. It will save results of some activation nodes. And the other will be recalculated in backward processing.&lt;/p&gt;

&lt;p&gt;https://pytorch.org/docs/stable/checkpoint.html&lt;/p&gt;

&lt;p&gt;Normally, with big deeplearning model, with limit memory of GPU, we must train 1 by 1 sample per step. So the gradient is quite noisy. One technique used in this case is gradient-average (Accumulating gradients)&lt;/p&gt;

&lt;p&gt;https://gchlebus.github.io/2018/06/05/gradient-averaging.html&lt;/p&gt;</content><author><name></name></author><summary type="html">Training with memory limit</summary></entry><entry><title type="html">Note of compare vector ptr and obj</title><link href="http://localhost:4000/2020/03/24/note-of-compare-vector-ptr-and-obj/" rel="alternate" type="text/html" title="Note of compare vector ptr and obj" /><published>2020-03-24T03:28:22+07:00</published><updated>2020-03-24T03:28:22+07:00</updated><id>http://localhost:4000/2020/03/24/note-of-compare-vector-ptr-and-obj</id><content type="html" xml:base="http://localhost:4000/2020/03/24/note-of-compare-vector-ptr-and-obj/">&lt;p&gt;Blog: https://www.bfilipek.com/2014/05/vector-of-objects-vs-vector-of-pointers.html&lt;/p&gt;

&lt;p&gt;Source: https://github.com/fenbf/PointerAccessTest&lt;/p&gt;

&lt;p&gt;Benchmark: http://quick-bench.com/VtyucjvZtTHo0czC96LARyWg_VU&lt;/p&gt;

&lt;p&gt;In this blog post, the author Bartlomiej Filipek wrote about the difference of vector of ptr and obj in two operations of updating and sorting.&lt;/p&gt;

&lt;p&gt;In updating, vector of object give a better performance than pointer. Because of when processing ptr, the memory of data is located somewhere rather than in a continuous memory of vector of object.&lt;/p&gt;

&lt;p&gt;And in sorting, sorting of ptr is faster. Because of moving object (swap) inside of vector is heavier than ptr.&lt;/p&gt;

&lt;p&gt;One good think is I could see a QuickBench which is used to create a fast benchmark to check code faster. It is very interesting tool. http://quick-bench.com/&lt;/p&gt;

&lt;p&gt;QuickBench uses Google benchmark library https://github.com/google/benchmark&lt;/p&gt;</content><author><name></name></author><summary type="html">Blog: https://www.bfilipek.com/2014/05/vector-of-objects-vs-vector-of-pointers.html</summary></entry><entry><title type="html">AI Model deployment</title><link href="http://localhost:4000/2020/02/13/ai-model-deployment/" rel="alternate" type="text/html" title="AI Model deployment" /><published>2020-02-13T10:14:37+07:00</published><updated>2020-02-13T10:14:37+07:00</updated><id>http://localhost:4000/2020/02/13/ai-model-deployment</id><content type="html" xml:base="http://localhost:4000/2020/02/13/ai-model-deployment/">&lt;ol&gt;
&lt;li&gt;Create queue services:&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Create a queue service including 3 task:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Add job to queue&lt;/li&gt;
&lt;li&gt;Check job status&lt;/li&gt;
&lt;li&gt;Process job&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Using MLQ&lt;/p&gt;

&lt;p&gt;https://towardsdatascience.com/there-are-two-very-different-ways-to-deploy-ml-models-heres-both-ce2e97c7b9b1&lt;/p&gt;

&lt;p&gt;Try to use CICD to increase deployment :&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/6987e-1bit0ilfcx9ntpgxo7fxwtw.png&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Alternatives:&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Combine&lt;/p&gt;

&lt;p&gt;https://github.com/tensorflow/serving&lt;/p&gt;

&lt;p&gt;https://opensource.googleblog.com/2016/02/running-your-models-in-production-with.html&lt;/p&gt;

&lt;p&gt;Tensorflow Serving, it is opensource, so we could serve ourselves for model prediction.&lt;/p&gt;

&lt;p&gt;https://eng.uber.com/michelangelo/&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/image8.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;A development and deployment model from Michelangelo Uber.&lt;/p&gt;

&lt;p&gt;https://blog.usejournal.com/a-guide-to-deploying-machine-deep-learning-model-s-in-production-e497fd4b734a&lt;/p&gt;</content><author><name></name></author><summary type="html">Create queue services:</summary></entry><entry><title type="html">Branch Prediction</title><link href="http://localhost:4000/2020/02/12/branch-prediction/" rel="alternate" type="text/html" title="Branch Prediction" /><published>2020-02-12T06:20:31+07:00</published><updated>2020-02-12T06:20:31+07:00</updated><id>http://localhost:4000/2020/02/12/branch-prediction</id><content type="html" xml:base="http://localhost:4000/2020/02/12/branch-prediction/">&lt;p&gt;It is a great day when I read an interesting post in Stackoverflow about branch prediction.&lt;/p&gt;

&lt;p&gt;It is an interesting question and answer.&lt;/p&gt;

&lt;p&gt;https://stackoverflow.com/questions/11227809/why-is-processing-a-sorted-array-faster-than-processing-an-unsorted-array?r=SearchResults&lt;/p&gt;

&lt;p&gt;The author find a difference in time performance of a loop with a condition inside.&lt;br /&gt;
The loop run faster with a sorted array. The loop run a lot slower with unsorted array.&lt;/p&gt;

&lt;p&gt;So the key is if-then-else condition in it. Because with a sorted array, most of the first haft part not run into if condition, the second part run into else condition. So with the instructions generated by compiler, it runs smoothly.&lt;/p&gt;

&lt;p&gt;But with an unsorted array, it not runs smoothly because it must switch in if/else condition.&lt;/p&gt;

&lt;p&gt;So I think the optimization is very interesting in this case. We could optimize it by rewrite the if/else condition into single sentence.&lt;/p&gt;

&lt;p&gt;Summary:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Limit of conditional instruction.&lt;/li&gt;
&lt;li&gt;Rewrite conditional may cause a difficulty in understanding code.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">It is a great day when I read an interesting post in Stackoverflow about branch prediction.</summary></entry><entry><title type="html">Compile Tensorflow v2.x on Windows</title><link href="http://localhost:4000/2019/12/03/compile-tensorflow-v2-x-on-windows/" rel="alternate" type="text/html" title="Compile Tensorflow v2.x on Windows" /><published>2019-12-03T09:54:58+07:00</published><updated>2019-12-03T09:54:58+07:00</updated><id>http://localhost:4000/2019/12/03/compile-tensorflow-v2-x-on-windows</id><content type="html" xml:base="http://localhost:4000/2019/12/03/compile-tensorflow-v2-x-on-windows/">&lt;p&gt;Build it as link https://www.tensorflow.org/install/source_windows&lt;/p&gt;

&lt;p&gt;Note:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Download Bazelick and rename it to bazel&lt;/li&gt;
&lt;li&gt;Add to bazel folder to PATH&lt;/li&gt;
&lt;li&gt;Install Msys64&lt;/li&gt;
&lt;li&gt;Install python numpy package&lt;/li&gt;
&lt;li&gt;Run on virtualenv&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;https://gist.github.com/thuanvh/04e34f1a74c2e6be79ae72a8906cc47d&lt;/p&gt;

&lt;p&gt;Binaries Download:&lt;/p&gt;

&lt;p&gt;Tensorflow 2.1.0-rc1 windows:&lt;/p&gt;

&lt;p&gt;https://github.com/thuanvh/tensorflow/releases/tag/2.1.0-rc1-win-x64-avx&lt;/p&gt;</content><author><name></name></author><summary type="html">Build it as link https://www.tensorflow.org/install/source_windows</summary></entry><entry><title type="html">GAN Links</title><link href="http://localhost:4000/2019/11/22/gan-links/" rel="alternate" type="text/html" title="GAN Links" /><published>2019-11-22T03:42:06+07:00</published><updated>2019-11-22T03:42:06+07:00</updated><id>http://localhost:4000/2019/11/22/gan-links</id><content type="html" xml:base="http://localhost:4000/2019/11/22/gan-links/">&lt;p&gt;PGGAN models &lt;a href=&quot;https://drive.google.com/open?id=15hvzxt_XxuokSmj0uO4xxMTMWVc0cIMU&quot;&gt;Model&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;StyleGAN model &lt;a href=&quot;https://drive.google.com/drive/folders/1MASQyN5m0voPcx7-9K0r5gObhvvPups7&quot;&gt;Model&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The implementation of StyleGAN &lt;a href=&quot;https://github.com/NVlabs/stylegan&quot;&gt;Model&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The implementation of BigGAN &lt;a href=&quot;https://github.com/ajbrock/BigGAN-PyTorch&quot;&gt;Model&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">PGGAN models Model</summary></entry><entry><title type="html">Brief SGD</title><link href="http://localhost:4000/2019/11/18/brief-sgd/" rel="alternate" type="text/html" title="Brief SGD" /><published>2019-11-18T08:23:44+07:00</published><updated>2019-11-18T08:23:44+07:00</updated><id>http://localhost:4000/2019/11/18/brief-sgd</id><content type="html" xml:base="http://localhost:4000/2019/11/18/brief-sgd/">&lt;p&gt;https://www.datasciencecentral.com/profiles/blogs/a-brief-and-comprehensive-guide-to-stochastic-gradient-descent&lt;/p&gt;

&lt;p&gt;In the above reference, it displays some idea of some SGD optimization in a short way which support us to summarize important ideas of SGD.&lt;/p&gt;

&lt;p&gt;SGD&lt;/p&gt;

&lt;p&gt;Gradient Perturbation : Add small noisy term to gradient.&lt;/p&gt;

&lt;p&gt;Momentum and Nesterov Momentum : Add a correction factor (a history of gradient change, exponentially weighted moving average) to gradient.&lt;/p&gt;

&lt;p&gt;RMSProp : Adapt correction factor to each parameter.&lt;/p&gt;</content><author><name></name></author><summary type="html">https://www.datasciencecentral.com/profiles/blogs/a-brief-and-comprehensive-guide-to-stochastic-gradient-descent</summary></entry><entry><title type="html">Very good write for eigendecomposition</title><link href="http://localhost:4000/2019/11/15/very-good-write-for-eigendecomposition/" rel="alternate" type="text/html" title="Very good write for eigendecomposition" /><published>2019-11-15T09:27:12+07:00</published><updated>2019-11-15T09:27:12+07:00</updated><id>http://localhost:4000/2019/11/15/very-good-write-for-eigendecomposition</id><content type="html" xml:base="http://localhost:4000/2019/11/15/very-good-write-for-eigendecomposition/">&lt;p&gt;http://www.deeplearningbook.org/contents/linear_algebra.html&lt;/p&gt;

&lt;p&gt;Eigen Decomposition&lt;/p&gt;
&lt;blockquote&gt;
&lt;div&gt;
&lt;div class=&quot;t m2 x1 h3 y1de ff3 fs2 fc0 sc0 ls0 ws0&quot;&gt;One of the most widely used kinds of matrix decomposition is called eigen-decomposition, in which we decompose a matrix into a set of eigenvectors and&lt;/div&gt;
&lt;div class=&quot;t m0 x0 h3 y1e0 ff3 fs2 fc0 sc0 ls0 ws0&quot;&gt;eigenvalues.&lt;/div&gt;
&lt;div class=&quot;t m17 x1 h3 y9c ff3 fs2 fc0 sc0 ls0 ws0&quot;&gt;An eigenvector of a square matrix A is a nonzero vector v such that multiplication by &lt;span class=&quot;ffb&quot;&gt;A &lt;/span&gt;alters only the scale of &lt;span class=&quot;ffb&quot;&gt;v&lt;/span&gt;:&lt;/div&gt;
&lt;div class=&quot;t m0 x56 h3 y1e1 ffb fs2 fc0 sc0 ls0 ws0&quot;&gt;Av &lt;span class=&quot;ffe&quot;&gt;= &lt;span class=&quot;ff9&quot;&gt;λ&lt;/span&gt;&lt;/span&gt;v&lt;span class=&quot;ff9&quot;&gt;. &lt;span class=&quot;ff3&quot;&gt;(2.39)&lt;/span&gt;&lt;/span&gt;&lt;/div&gt;
&lt;div class=&quot;t mf x5 h3 y1e2 ff3 fs2 fc0 sc0 ls0 ws0&quot;&gt;The scalar λ is known as the eigenvalue corresponding to this eigenvector. (One can also ﬁnd a left eigenvector such that vA=λ&lt;span class=&quot;ffb&quot;&gt;v&lt;/span&gt;, but we are usually concerned with right eigenvectors.)&lt;/div&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;div class=&quot;t mf x5 h3 y1e2 ff3 fs2 fc0 sc0 ls0 ws0&quot;&gt;SVD (p.42)&lt;/div&gt;
&lt;div&gt;&lt;/div&gt;
&lt;blockquote&gt;
&lt;div id=&quot;pfe&quot; class=&quot;pf w0 h0&quot;&gt;
&lt;div class=&quot;pc pce w0 h0 opened&quot;&gt;
&lt;div class=&quot;t m2 x5 h3 y245 ff3 fs2 fc0 sc0 ls0 ws0&quot;&gt;The singular value decomposition (SVD) provides another way to factorize a matrix, into &lt;strong&gt;singular vectors&lt;/strong&gt; and &lt;strong&gt;singular values&lt;/strong&gt;. The SVD enables us to&lt;/div&gt;
&lt;div class=&quot;t m5 x0 h3 y247 ff3 fs2 fc0 sc0 ls0 ws0&quot;&gt;discover some of the same kind of information as the eigendecomposition reveals;&lt;/div&gt;
&lt;div class=&quot;t m12 x0 h3 y248 ff3 fs2 fc0 sc0 ls0 ws0&quot;&gt;however, the SVD is more generally applicable. Every real matrix has a singular&lt;/div&gt;
&lt;div class=&quot;t m2 x5 h3 y249 ff3 fs2 fc0 sc0 ls0 ws0&quot;&gt;value decomposition, but the same is not true of the eigenvalue decomposition.&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&quot;pff&quot; class=&quot;pf w0 h0&quot;&gt;
&lt;div class=&quot;pc pcf w0 h0 opened&quot;&gt;
&lt;div class=&quot;t m6 x0 h3 y1a ff3 fs2 fc0 sc0 ls0 ws0&quot;&gt;For example, if a matrix is not square, the eigendecomposition is not deﬁned, and&lt;/div&gt;
&lt;div class=&quot;t m0 x5 h3 y1b ff3 fs2 fc0 sc0 ls0 ws0&quot;&gt;we must use a singular value decomposition instead.&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/blockquote&gt;</content><author><name></name></author><summary type="html">http://www.deeplearningbook.org/contents/linear_algebra.html</summary></entry></feed>