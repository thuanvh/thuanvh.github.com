<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-05-03T16:36:56+07:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">A bla bla developer blog</title><subtitle>Work note.</subtitle><entry><title type="html">Python-coding-style</title><link href="http://localhost:4000/jekyll/update/2020/05/03/python-coding-style.html" rel="alternate" type="text/html" title="Python-coding-style" /><published>2020-05-03T01:17:24+07:00</published><updated>2020-05-03T01:17:24+07:00</updated><id>http://localhost:4000/jekyll/update/2020/05/03/python-coding-style</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2020/05/03/python-coding-style.html">&lt;p&gt;After look up for coding convention for Python. I have read a few guide for python coding convention.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://docs.python-guide.org/writing/style/&quot;&gt;https://docs.python-guide.org/writing/style/&lt;/a&gt;
Firstly is coding style written by Hitchhiker.&lt;/p&gt;

&lt;p&gt;In summary for tldr;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Explicit code. Should write as normal thinking of people&lt;/li&gt;
  &lt;li&gt;One state per line. As many languages convention, one line for one state&lt;/li&gt;
  &lt;li&gt;Avoid magic wand. 
Avoid hacking (change the way object instantiated, created, change the way python import modules, embeded C into python).
We should avoid all of them, just keep the way straitforward as it is. That could reduce readibility, code analysis tool such as pylint,
pyflakes.&lt;/li&gt;
  &lt;li&gt;We are all reponsible user.
In python there is many tricks. So we must be responsible.&lt;/li&gt;
  &lt;li&gt;Returning value.
Keep single exit point is better. Should not return in the middle.&lt;/li&gt;
  &lt;li&gt;PEP 8 for style check &lt;a href=&quot;https://www.python.org/dev/peps/pep-0008&quot;&gt;https://www.python.org/dev/peps/pep-0008&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;PEP 20 for general guideline &lt;a href=&quot;https://www.python.org/dev/peps/pep-0020&quot;&gt;https://www.python.org/dev/peps/pep-0020&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;https://www.geeksforgeeks.org/10-essential-python-tips-tricks-programmers&quot;&gt;https://www.geeksforgeeks.org/10-essential-python-tips-tricks-programmers&lt;/a&gt;
&lt;a href=&quot;https://www.techbeamers.com/essential-python-tips-tricks-programmers&quot;&gt;https://www.techbeamers.com/essential-python-tips-tricks-programmers&lt;/a&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;swap
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;x, y = y, x
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;reverse a string
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;a = &quot;abc&quot;
print(a[::-1])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;string concatenation
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;a = [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;]
print(&quot;&quot;.join(a))
print(&quot; &quot;.join(a))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;chaining of comparion
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;a = 10
print(1 &amp;lt; a &amp;lt;= 20)
print(1 &amp;gt; a &amp;lt;= 9)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;know where is module located
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import os
print(os)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;enum in python
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;class A:
 E1, E2, E3 = range(3)
print(A.E1, A.E2, A.E3)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;use dictionary for switch&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;stdcalc = {
	'sum': lambda x, y: x + y,
	'subtract': lambda x, y: x - y
}

print(stdcalc['sum'](9,3))
print(stdcalc['subtract'](9,3))

Output:
#1-&amp;gt; 12
#2-&amp;gt; 6
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ol&gt;
  &lt;li&gt;most frequent array&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;test = [1,2,3,4,2,2,3,1,4,4,4]
print(max(set(test), key=test.count))

#-&amp;gt; 4
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ol&gt;
  &lt;li&gt;reset recursion limit&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import sys

x=1001
print(sys.getrecursionlimit())

sys.setrecursionlimit(x)
print(sys.getrecursionlimit())

#1-&amp;gt; 1000
#2-&amp;gt; 1001
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ol&gt;
  &lt;li&gt;check memory of object&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import sys
x=1
print(sys.getsizeof(x))

#-&amp;gt; 24
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ol&gt;
  &lt;li&gt;use &lt;strong&gt;slots&lt;/strong&gt; to reduce memory overheads&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import sys
class FileSystem(object):

	def __init__(self, files, folders, devices):
		self.files = files
		self.folders = folders
		self.devices = devices

print(sys.getsizeof( FileSystem ))

class FileSystem1(object):

	__slots__ = ['files', 'folders', 'devices']
	
	def __init__(self, files, folders, devices):
		self.files = files
		self.folders = folders
		self.devices = devices

print(sys.getsizeof( FileSystem1 ))

#In Python 3.5
#1-&amp;gt; 1016
#2-&amp;gt; 888
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ol&gt;
  &lt;li&gt;Search prefix or suffix&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;print(&quot;http://www.google.com&quot;.startswith((&quot;http://&quot;, &quot;https://&quot;)))
print(&quot;http://www.google.co.uk&quot;.endswith((&quot;.com&quot;, &quot;.co.uk&quot;)))

#1-&amp;gt; True
#2-&amp;gt; True
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ol&gt;
  &lt;li&gt;Switch case&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def xswitch(x): 
	return xswitch._system_dict.get(x, None) 

xswitch._system_dict = {'files': 10, 'folders': 5, 'devices': 2}

print(xswitch('default'))
print(xswitch('devices'))

#1-&amp;gt; None
#2-&amp;gt; 2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name></name></author><summary type="html">After look up for coding convention for Python. I have read a few guide for python coding convention.</summary></entry><entry><title type="html">Welcome to Jekyll!</title><link href="http://localhost:4000/jekyll/update/2020/05/02/welcome-to-jekyll.html" rel="alternate" type="text/html" title="Welcome to Jekyll!" /><published>2020-05-02T01:17:24+07:00</published><updated>2020-05-02T01:17:24+07:00</updated><id>http://localhost:4000/jekyll/update/2020/05/02/welcome-to-jekyll</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2020/05/02/welcome-to-jekyll.html">&lt;p&gt;Youâ€™ll find this post in your &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_posts&lt;/code&gt; directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;jekyll serve&lt;/code&gt;, which launches a web server and auto-regenerates your site when a file is updated.&lt;/p&gt;

&lt;p&gt;To add new posts, simply add a file in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_posts&lt;/code&gt; directory that follows the convention &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;YYYY-MM-DD-name-of-post.ext&lt;/code&gt; and includes the necessary front matter. Take a look at the source for this post to get an idea about how it works.&lt;/p&gt;

&lt;p&gt;Jekyll also offers powerful support for code snippets:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;print_hi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;nb&quot;&gt;puts&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Hi, &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;#{&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;print_hi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'Tom'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#=&amp;gt; prints 'Hi, Tom' to STDOUT.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Check out the &lt;a href=&quot;https://jekyllrb.com/docs/home&quot;&gt;Jekyll docs&lt;/a&gt; for more info on how to get the most out of Jekyll. File all bugs/feature requests at &lt;a href=&quot;https://github.com/jekyll/jekyll&quot;&gt;Jekyllâ€™s GitHub repo&lt;/a&gt;. If you have questions, you can ask them on &lt;a href=&quot;https://talk.jekyllrb.com/&quot;&gt;Jekyll Talk&lt;/a&gt;.&lt;/p&gt;</content><author><name></name></author><summary type="html">Youâ€™ll find this post in your _posts directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run jekyll serve, which launches a web server and auto-regenerates your site when a file is updated.</summary></entry><entry><title type="html">Speed up python code</title><link href="http://localhost:4000/2020/04/03/speed-up-python-code/" rel="alternate" type="text/html" title="Speed up python code" /><published>2020-04-03T05:58:57+07:00</published><updated>2020-04-03T05:58:57+07:00</updated><id>http://localhost:4000/2020/04/03/speed-up-python-code</id><content type="html" xml:base="http://localhost:4000/2020/04/03/speed-up-python-code/">&lt;p&gt;https://towardsdatascience.com/how-to-speed-up-your-python-code-d31927691012&lt;/p&gt;

&lt;p&gt;I have read a few analyse in using python :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Optimize your code first&lt;/li&gt;
  &lt;li&gt;Use pypy library&lt;/li&gt;
  &lt;li&gt;Use multithread for IO bound or asyncio&lt;/li&gt;
  &lt;li&gt;Use multiprocess for CPU bound&lt;/li&gt;
  &lt;li&gt;Use hadoop for distributed computing for move to cloud&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">https://towardsdatascience.com/how-to-speed-up-your-python-code-d31927691012</summary></entry><entry><title type="html">Training Parallelism</title><link href="http://localhost:4000/2020/03/28/training-parallelism/" rel="alternate" type="text/html" title="Training Parallelism" /><published>2020-03-28T16:46:30+07:00</published><updated>2020-03-28T16:46:30+07:00</updated><id>http://localhost:4000/2020/03/28/training-parallelism</id><content type="html" xml:base="http://localhost:4000/2020/03/28/training-parallelism/">&lt;p&gt;&lt;strong&gt;Training with memory limit&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;One of interesting test about training with memory limit. He use the way to store some nodes in forward steps (not all nodes). Then in backward steps, he recalculate some forward steps (which is not stored) for gradient calculation. The nodes indexes which are stored are sqrt(i)-th node.&lt;/p&gt;

&lt;p&gt;https://github.com/cybertronai/gradient-checkpointing&lt;/p&gt;

&lt;p&gt;And he wrote a post about this technique:&lt;/p&gt;

&lt;p&gt;https://medium.com/tensorflow/fitting-larger-networks-into-memory-583e3c758ff9&lt;/p&gt;

&lt;p&gt;And the checkpoint concept is used in PyTorch also. The same concept with the above idea. It will save results of some activation nodes. And the other will be recalculated in backward processing.&lt;/p&gt;

&lt;p&gt;https://pytorch.org/docs/stable/checkpoint.html&lt;/p&gt;

&lt;p&gt;Normally, with big deeplearning model, with limit memory of GPU, we must train 1 by 1 sample per step. So the gradient is quite noisy. One technique used in this case is gradient-average (Accumulating gradients)&lt;/p&gt;

&lt;p&gt;https://gchlebus.github.io/2018/06/05/gradient-averaging.html&lt;/p&gt;</content><author><name></name></author><summary type="html">Training with memory limit</summary></entry><entry><title type="html">Note of compare vector ptr and obj</title><link href="http://localhost:4000/2020/03/24/note-of-compare-vector-ptr-and-obj/" rel="alternate" type="text/html" title="Note of compare vector ptr and obj" /><published>2020-03-24T03:28:22+07:00</published><updated>2020-03-24T03:28:22+07:00</updated><id>http://localhost:4000/2020/03/24/note-of-compare-vector-ptr-and-obj</id><content type="html" xml:base="http://localhost:4000/2020/03/24/note-of-compare-vector-ptr-and-obj/">&lt;p&gt;Blog: &lt;a href=&quot;https://www.bfilipek.com/2014/05/vector-of-objects-vs-vector-of-pointers.html&quot;&gt;https://www.bfilipek.com/2014/05/vector-of-objects-vs-vector-of-pointers.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Source: &lt;a href=&quot;https://github.com/fenbf/PointerAccessTest&quot;&gt;https://github.com/fenbf/PointerAccessTest&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Benchmark: &lt;a href=&quot;http://quick-bench.com/VtyucjvZtTHo0czC96LARyWg_VU&quot;&gt;http://quick-bench.com/VtyucjvZtTHo0czC96LARyWg_VU&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In this blog post, the author Bartlomiej Filipek wrote about the difference of vector of ptr and obj in two operations of updating and sorting.&lt;/p&gt;

&lt;p&gt;In updating, vector of object give a better performance than pointer. Because of when processing ptr, the memory of data is located somewhere rather than in a continuous memory of vector of object.&lt;/p&gt;

&lt;p&gt;And in sorting, sorting of ptr is faster. Because of moving object (swap) inside of vector is heavier than ptr.&lt;/p&gt;

&lt;p&gt;One good think is I could see a QuickBench which is used to create a fast benchmark to check code faster. It is very interesting tool. &lt;a href=&quot;http://quick-bench.com&quot;&gt;http://quick-bench.com&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;QuickBench uses Google benchmark library &lt;a href=&quot;https://github.com/google/benchmark&quot;&gt;https://github.com/google/benchmark&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">Blog: https://www.bfilipek.com/2014/05/vector-of-objects-vs-vector-of-pointers.html</summary></entry><entry><title type="html">AI Model deployment</title><link href="http://localhost:4000/2020/02/13/ai-model-deployment/" rel="alternate" type="text/html" title="AI Model deployment" /><published>2020-02-13T10:14:37+07:00</published><updated>2020-02-13T10:14:37+07:00</updated><id>http://localhost:4000/2020/02/13/ai-model-deployment</id><content type="html" xml:base="http://localhost:4000/2020/02/13/ai-model-deployment/">&lt;ol&gt;
&lt;li&gt;Create queue services:&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Create a queue service including 3 task:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Add job to queue&lt;/li&gt;
&lt;li&gt;Check job status&lt;/li&gt;
&lt;li&gt;Process job&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Using MLQ&lt;/p&gt;

&lt;p&gt;https://towardsdatascience.com/there-are-two-very-different-ways-to-deploy-ml-models-heres-both-ce2e97c7b9b1&lt;/p&gt;

&lt;p&gt;Try to use CICD to increase deployment :&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/6987e-1bit0ilfcx9ntpgxo7fxwtw.png&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Alternatives:&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Combine&lt;/p&gt;

&lt;p&gt;https://github.com/tensorflow/serving&lt;/p&gt;

&lt;p&gt;https://opensource.googleblog.com/2016/02/running-your-models-in-production-with.html&lt;/p&gt;

&lt;p&gt;Tensorflow Serving, it is opensource, so we could serve ourselves for model prediction.&lt;/p&gt;

&lt;p&gt;https://eng.uber.com/michelangelo/&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/image8.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;A development and deployment model from Michelangelo Uber.&lt;/p&gt;

&lt;p&gt;https://blog.usejournal.com/a-guide-to-deploying-machine-deep-learning-model-s-in-production-e497fd4b734a&lt;/p&gt;</content><author><name></name></author><summary type="html">Create queue services:</summary></entry><entry><title type="html">Branch Prediction</title><link href="http://localhost:4000/2020/02/12/branch-prediction/" rel="alternate" type="text/html" title="Branch Prediction" /><published>2020-02-12T06:20:31+07:00</published><updated>2020-02-12T06:20:31+07:00</updated><id>http://localhost:4000/2020/02/12/branch-prediction</id><content type="html" xml:base="http://localhost:4000/2020/02/12/branch-prediction/">&lt;p&gt;It is a great day when I read an interesting post in Stackoverflow about branch prediction.&lt;/p&gt;

&lt;p&gt;It is an interesting question and answer.&lt;/p&gt;

&lt;p&gt;https://stackoverflow.com/questions/11227809/why-is-processing-a-sorted-array-faster-than-processing-an-unsorted-array?r=SearchResults&lt;/p&gt;

&lt;p&gt;The author find a difference in time performance of a loop with a condition inside.&lt;br /&gt;
The loop run faster with a sorted array. The loop run a lot slower with unsorted array.&lt;/p&gt;

&lt;p&gt;So the key is if-then-else condition in it. Because with a sorted array, most of the first haft part not run into if condition, the second part run into else condition. So with the instructions generated by compiler, it runs smoothly.&lt;/p&gt;

&lt;p&gt;But with an unsorted array, it not runs smoothly because it must switch in if/else condition.&lt;/p&gt;

&lt;p&gt;So I think the optimization is very interesting in this case. We could optimize it by rewrite the if/else condition into single sentence.&lt;/p&gt;

&lt;p&gt;Summary:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Limit of conditional instruction.&lt;/li&gt;
&lt;li&gt;Rewrite conditional may cause a difficulty in understanding code.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">It is a great day when I read an interesting post in Stackoverflow about branch prediction.</summary></entry><entry><title type="html">Compile Tensorflow v2.x on Windows</title><link href="http://localhost:4000/2019/12/03/compile-tensorflow-v2-x-on-windows/" rel="alternate" type="text/html" title="Compile Tensorflow v2.x on Windows" /><published>2019-12-03T09:54:58+07:00</published><updated>2019-12-03T09:54:58+07:00</updated><id>http://localhost:4000/2019/12/03/compile-tensorflow-v2-x-on-windows</id><content type="html" xml:base="http://localhost:4000/2019/12/03/compile-tensorflow-v2-x-on-windows/">&lt;p&gt;Build it as link https://www.tensorflow.org/install/source_windows&lt;/p&gt;

&lt;p&gt;Note:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Download Bazelick and rename it to bazel&lt;/li&gt;
&lt;li&gt;Add to bazel folder to PATH&lt;/li&gt;
&lt;li&gt;Install Msys64&lt;/li&gt;
&lt;li&gt;Install python numpy package&lt;/li&gt;
&lt;li&gt;Run on virtualenv&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;https://gist.github.com/thuanvh/04e34f1a74c2e6be79ae72a8906cc47d&lt;/p&gt;

&lt;p&gt;Binaries Download:&lt;/p&gt;

&lt;p&gt;Tensorflow 2.1.0-rc1 windows:&lt;/p&gt;

&lt;p&gt;https://github.com/thuanvh/tensorflow/releases/tag/2.1.0-rc1-win-x64-avx&lt;/p&gt;</content><author><name></name></author><summary type="html">Build it as link https://www.tensorflow.org/install/source_windows</summary></entry><entry><title type="html">GAN Links</title><link href="http://localhost:4000/2019/11/22/gan-links/" rel="alternate" type="text/html" title="GAN Links" /><published>2019-11-22T03:42:06+07:00</published><updated>2019-11-22T03:42:06+07:00</updated><id>http://localhost:4000/2019/11/22/gan-links</id><content type="html" xml:base="http://localhost:4000/2019/11/22/gan-links/">&lt;p&gt;PGGAN models &lt;a href=&quot;https://drive.google.com/open?id=15hvzxt_XxuokSmj0uO4xxMTMWVc0cIMU&quot;&gt;Model&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;StyleGAN model &lt;a href=&quot;https://drive.google.com/drive/folders/1MASQyN5m0voPcx7-9K0r5gObhvvPups7&quot;&gt;Model&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The implementation of StyleGAN &lt;a href=&quot;https://github.com/NVlabs/stylegan&quot;&gt;Model&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The implementation of BigGAN &lt;a href=&quot;https://github.com/ajbrock/BigGAN-PyTorch&quot;&gt;Model&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">PGGAN models Model</summary></entry><entry><title type="html">Brief SGD</title><link href="http://localhost:4000/2019/11/18/brief-sgd/" rel="alternate" type="text/html" title="Brief SGD" /><published>2019-11-18T08:23:44+07:00</published><updated>2019-11-18T08:23:44+07:00</updated><id>http://localhost:4000/2019/11/18/brief-sgd</id><content type="html" xml:base="http://localhost:4000/2019/11/18/brief-sgd/">&lt;p&gt;https://www.datasciencecentral.com/profiles/blogs/a-brief-and-comprehensive-guide-to-stochastic-gradient-descent&lt;/p&gt;

&lt;p&gt;In the above reference, it displays some idea of some SGD optimization in a short way which support us to summarize important ideas of SGD.&lt;/p&gt;

&lt;p&gt;SGD&lt;/p&gt;

&lt;p&gt;Gradient Perturbation : Add small noisy term to gradient.&lt;/p&gt;

&lt;p&gt;Momentum and Nesterov Momentum : Add a correction factor (a history of gradient change, exponentially weighted moving average) to gradient.&lt;/p&gt;

&lt;p&gt;RMSProp : Adapt correction factor to each parameter.&lt;/p&gt;</content><author><name></name></author><summary type="html">https://www.datasciencecentral.com/profiles/blogs/a-brief-and-comprehensive-guide-to-stochastic-gradient-descent</summary></entry></feed>